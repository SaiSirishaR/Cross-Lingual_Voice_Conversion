<html>
  <head>
  </head>
     <title>Cross-Lingual Voice Conversion</title>
  <body>
     <h1 align="center">An approach to Cross-Lingual Voice Conversion</h1>
     <h2 align="center"> Sai Sirisha Rallabandi and Suryakanth V Gangashetty</h2>
     <h3 align="center"> Speech Processing Laboratory</h3>
     <h4 align="center">International Institute of Information Technology Hyderabad</h4>

  <font size="4"> A simple approach to address the cross-lingual voice conversion has been proposed. We implement two variants of Neural Networks for the task. The two networks are: i) a traditional auto-encoder and ii) a conventional DNN . Utilizing an autoencoded speech has facilitated us with the parallel corpus for the cross-lingual conversion task. A pictographic representation of the same is displayed.</font></h4>
    
    <br>
    <br>
    
   
     <p align="center"><img src = "samples//picto_modified.png" alt = "Test Image"  width="540" height="250" /></p>

    <br>
    
    
  
  <p align="center"><font size="4"> Speech Samples thus obtained from the designed experiments are presented below.</font></p>

    
    <br>
     <table align="center" , border="1">
       <tr>
          <td><font size ="4" align="center">Chinese Voice </font></td><td><font size="4" align="center">English Voice</font></td><td><font size ="4" align="center">Converted Voice </font></td>
       </tr>
       <tr>
          <td> <audio controls><source src="samples/Chinese/text_00035.wav"></audio></td> <td><audio controls><source src="samples/slt/arctic_a0100.wav"></audio></td><td> <audio controls><source src="samples/clvc_output/arctic_a0100.wav"></audio></td></tr>

       <tr>
          <td> <audio controls><source src="samples/Chinese/text_00045.wav"></audio></td> <td><audio controls><source src="samples/slt/arctic_a0058.wav"></audio></td> <td><audio controls><source src="samples/clvc_output/arctic_a0058.wav"></audio></td></tr>
       <tr>
         <td> <audio controls><source src="samples/Chinese/text_00025.wav"></audio></td> <td><audio controls><source src="samples/slt/arctic_a0135.wav"></audio></td> <td> <audio controls><source src="samples/clvc_output/arctic_a0135.wav"></audio></td></tr>

       <tr>
         <td> <audio controls><source src="samples/Chinese/text_00015.wav"></audio></td> <td><audio controls><source src="samples/slt/arctic_a0306.wav"></audio></td> <td> <audio controls><source src="samples/clvc_output/arctic_a0306.wav"></audio></td></tr>
     </table>
  <h4> Acknowledgements</h4> 
  <p> We would like to thank Minghui Dong for providing the Blizzard 2010 Chinese dataset for our experiments. Authors would like to thank Berrak Sisman and Mingyang Zhang for their valuable discussions and suggestions. First author was partially funded by the grants R-263-000-C35-731 and R-263-000-C35-133 under the Voice Morphing project at National University of Singapore for this work. We would like to thank all the listeners for their participation in the subjective evaluation. </p>
  </body>
</html>
